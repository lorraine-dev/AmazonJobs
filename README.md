# Amazon + TheirStack Jobs Dashboard

A personal dashboard that automatically scrapes Amazon Jobs Luxembourg and displays the results as a web dashboard.

---

## ğŸš€ Overview

This project:
- **Scrapes Amazon Jobs** and **TheirStack** jobs (scheduled via GitHub Actions)
- **Combines raw CSVs** into a unified `data/processed/combined_jobs.csv`
- **Generates the dashboard** from the combined CSV
- **Deploys to GitHub Pages** (auto-updating dashboard)

---

## ğŸ“Š Dashboard

The dashboard shows:
- **Job statistics** (total, active, inactive)
- **Job listings** in a scrollable table with sorting, filtering, and searching capabilities.
- **Key job details** (title, role, team, category, posting date).
- **Interactive data visualizations**, including a Sankey diagram and a skill-prevalence chart.
- **Direct links** to job applications.

---

## ğŸ› ï¸ Technology Stack

- **Python** (Pandas, Requests, BeautifulSoup, PyYAML, Plotly, python-dotenv, langdetect)
- **Optional engine**: Selenium + webdriver-manager (install via extras: `pip install '.[selenium]'`)
- **Dev/optional**: lxml, nbformat (used for notebooks and optional HTML/XML parsing backends)
- **GitHub Actions** (automation)
- **GitHub Pages** (hosting)

---

## ğŸ“ Project Structure

```
â”œâ”€â”€ .github/workflows/scraper.yml            # Automated workflow (scrape, combine, deploy)
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ scraper_config.yaml                  # Source configs and limits
â”‚   â”œâ”€â”€ category_mapping.yaml                # Mapping rules for categories
â”‚   â””â”€â”€ theirstack_titles.json               # Title normalization hints for TheirStack
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ index.html                           # Dashboard (auto-generated)
â”‚   â”œâ”€â”€ style.css                            # Main dashboard styles
â”‚   â”œâ”€â”€ skills.css                           # Skills visualization styles
â”‚   â”œâ”€â”€ dashboard_interactions.js            # Client-side interactions
â”‚   â””â”€â”€ reference/                           # API/reference assets
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ scraper/
â”‚   â”‚   â”œâ”€â”€ amazon_scraper.py                # Legacy/simple Amazon scraper
â”‚   â”‚   â”œâ”€â”€ amazon_api_scraper.py            # Amazon Jobs API scraper
â”‚   â”‚   â”œâ”€â”€ amazon_selenium_scraper.py       # Amazon Selenium scraper
â”‚   â”‚   â”œâ”€â”€ theirstack_scraper.py            # TheirStack API scraper
â”‚   â”‚   â”œâ”€â”€ theirstack_processor.py          # TheirStack â†’ unified schema
â”‚   â”‚   â”œâ”€â”€ config.py                        # Scraper config helpers
â”‚   â”‚   â””â”€â”€ engines.py                       # Scraper engines
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ paths.py                         # Centralized path helpers
â”‚   â”‚   â”œâ”€â”€ category_mapper.py               # Category inference
â”‚   â”‚   â”œâ”€â”€ raw_storage.py                   # Unified raw CSV writer with dedupe
â”‚   â”‚   â”œâ”€â”€ combine_jobs.py                  # Merge raw CSVs â†’ combined CSV
â”‚   â”‚   â”œâ”€â”€ data_analytics.py                # Skill breakdown analytics
â”‚   â”‚   â”œâ”€â”€ data_processor.py                # Dashboard generator
â”‚   â”‚   â”œâ”€â”€ dashboard_template.py            # HTML template generator
â”‚   â”‚   â”œâ”€â”€ dashboard_visuals.py             # Sankey diagram and visuals
â”‚   â”‚   â”œâ”€â”€ description_parser.py            # JD section parser
â”‚   â”‚   â”œâ”€â”€ logging_utils.py                 # Logging configuration utilities
â”‚   â”‚   â”œâ”€â”€ health_check.py                  # Pre-flight checks and validations
â”‚   â”‚   â”œâ”€â”€ monitoring.py                    # Simple runtime metrics
â”‚   â”‚   â”œâ”€â”€ text_lang.py                     # Language detection helpers
â”‚   â”‚   â””â”€â”€ theirstack_state.py              # TheirStack incremental state
â”‚   â””â”€â”€ scripts/
â”‚       â””â”€â”€ run_scraper.py                   # Unified runner (CLI)
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                                 # Raw per-source CSVs (artifacts)
â”‚   â”œâ”€â”€ processed/
â”‚   â”‚   â””â”€â”€ combined_jobs.csv                # Unified CSV for dashboard
â”‚   â””â”€â”€ backups/                             # TheirStack request/response backups
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ setup.py
â””â”€â”€ .gitignore
```

---

## âš¡ Usage

### View the Dashboard

- Visit the [GitHub Pages site](https://lorraine-dev.github.io/AmazonJobs/) (auto-updated after each scheduled run).

### Run Locally (Advanced)

1. Clone the repository.
2. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```
   If you plan to use the Selenium engine, install the optional extras:
   ```bash
   pip install '.[selenium]'
   ```
3. Create a `.env` file in the repo root (not committed):
   ```env
   THEIR_STACK_API_KEY=your_theirstack_token_here
   ```
4. Edit `config/scraper_config.yaml` if needed.
5. Run the unified scraper:
   ```bash
   python src/scripts/run_scraper.py
   ```
   Optional:
   ```bash
   # Run only TheirStack and skip dashboard
   python src/scripts/run_scraper.py --source theirstack --skip-dashboard

   # Run only Amazon
   python src/scripts/run_scraper.py --source amazon

   # Force Amazon engine (API or Selenium)
   python src/scripts/run_scraper.py --source amazon --amazon-engine api
   python src/scripts/run_scraper.py --source amazon --amazon-engine selenium
   ```
6. Generate the dashboard (if needed):
   ```bash
   python src/utils/data_processor.py
   ```

---

## âš™ï¸ Configuration

Edit `config/scraper_config.yaml` to change scraping parameters (e.g., base URL, number of workers).

### HTTP reliability settings
- `common.http_retries` (default: 3) â€” Retry count for transient errors (429, 5xx) with exponential backoff.
- `common.http_backoff` (default: 0.5) â€” Backoff factor used for retries.

These apply to both Amazon API and TheirStack requests via a shared retrying HTTP session.

### Rate limiting (optional)
- `common.http_min_interval_seconds` (default: 0.0) â€” Minimum delay between paginated requests.
- `common.http_jitter_seconds` (default: 0.0) â€” Extra random delay added on top of `min_interval` (uniform in [0, jitter]).

If set, these throttle page-by-page calls in both scrapers to avoid rate limits.

### TheirStack request settings
- `theirstack.timeout_precheck` (default: 10s) â€” Timeout for the initial free pre-check calls.
- `theirstack.timeout_paid` (default: 15s) â€” Timeout for the paid paginated fetch calls.
- `theirstack.wide_fetch_limit` (default: 10) â€” Max jobs to fetch in the optional wide pre-check flow when pre-check finds nothing for the last-run window.

All settings are optional; sensible defaults are used if keys are absent.

---

## ğŸ¤– Automation

- **GitHub Actions** runs 3x daily at 08:00, 14:00, and 18:00 UTC (see `.github/workflows/scraper.yml`).
- You can also run it manually and choose the Amazon engine via the `amazon_engine` input (defaults to `api`).
- Secrets: add `THEIR_STACK_API_KEY` under Settings â†’ Secrets and variables â†’ Actions.
- Artifacts persisted between runs:
  - `job-data`: contents of `data/raw/` (raw CSVs)
  - `job-state`: `theirstack_state.json` (incremental scraping state)
  - `job-backups`: contents of `data/backups/` (request/response backups)
- The workflow includes a pre-run check step to ensure `THEIR_STACK_API_KEY` is present.

## ğŸ”„ Dependency updates (Renovate)

- **What it is**: A hosted GitHub App that scans this repo and opens PRs to keep dependencies up to date. Zero runtime/storage footprint in this repo beyond a small config file.
- **What it does here**:
  - Monitors `.github/workflows/*.yml` for `uses: owner/repo@...` entries.
  - Keeps GitHub Actions pinned to commit SHAs for determinism and proposes PRs when the major tag (`v3`, `v4`, ...) advances.
- **Setup**:
  1. Install the Renovate GitHub App and grant it access to this repository.
  2. Ensure `renovate.json` exists at the repo root (already included) with the `github-actions` manager enabled and `pinDigests: true`.
  3. Renovate will open PRs grouped as "GitHub Actions updates" on the schedule `before 6am on monday`.
- **Adjust behavior**:
  - To auto-merge safe updates, set `"automerge": true` in the matching `packageRules`.
  - To stop pinning to SHAs (not recommended), set `"pinDigests": false`.
- **Docs**: https://docs.renovatebot.com

---

## ğŸ§ª Troubleshooting

- **Secret missing**: Workflow fails at step "Check TheirStack secret presence". Add `THEIR_STACK_API_KEY` in repo Settings.
- **No combined CSV**: Ensure raw CSVs exist in `data/raw/`. The combiner `src/utils/combine_jobs.py` writes `data/processed/combined_jobs.csv`.
- **Dashboard error page**: See `docs/index.html` content for the error message. Check logs in the workflow run.
- **TheirStack API issues**: Inspect JSON backups in `data/backups/` (also uploaded as `job-backups` artifact) and adjust filters in `config/scraper_config.yaml`.

---

## ğŸ“ License

Personal project. For educational and personal use only.

---

*Last updated: Automatically updated via GitHub Actions*
